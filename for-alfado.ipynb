{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-02 15:28:10] (2.3.1) \u001B[31mPyABSA(2.3.1): If your code crashes on Colab, please use the GPU runtime. Then run \"pip install pyabsa[dev] -U\" and restart the kernel.\n",
      "Or if it does not work, you can use v1.16.27\n",
      "\n",
      "[New Feature] Aspect Sentiment Triplet Extraction since v2.1.0 (https://github.com/yangheng95/PyABSA/tree/v2/examples-v2/aspect_sentiment_triplet_extration)\n",
      "[New Feature] Aspect CategoryOpinion Sentiment Quadruple Extraction since v2.2.0 (https://github.com/yangheng95/PyABSA/tree/v2/examples-v2/aspect_opinion_sentiment_category_extraction)\n",
      "\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\envs\\PyABSA\\lib\\multiprocessing\\pool.py:265: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.Pool state=RUN pool_size=1>\n",
      "  _warn(f\"unclosed running multiprocessing pool {self!r}\",\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "from pyabsa import AspectTermExtraction as ATEPC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "config = (\n",
    "    ATEPC.ATEPCConfigManager.get_atepc_config_english()\n",
    ")  # this config contains 'pretrained_bert', it is based on pretrained models\n",
    "config.model = ATEPC.ATEPCModelList.FAST_LCF_ATEPC  # improved version of LCF-ATEPC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from pyabsa import DatasetItem\n",
    "\n",
    "dataset = DatasetItem(\"AttractionReviewEn\", \"1.TripAdvisor\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['1.TripAdvisor']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-02 15:28:34] (2.3.1) Set Model Device: cuda:0\n",
      "[2023-05-02 15:28:34] (2.3.1) Device Name: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "2023-05-02 15:28:35,210 INFO: PyABSA version: 2.3.1\n",
      "2023-05-02 15:28:35,211 INFO: Transformers version: 4.28.1\n",
      "2023-05-02 15:28:35,211 INFO: Torch version: 2.0.0+cuda11.8\n",
      "2023-05-02 15:28:35,211 INFO: Device: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "2023-05-02 15:28:35,212 INFO: AttractionReviewEn in the trainer is not a exact path, will search dataset in current working directory\n",
      "2023-05-02 15:28:36,281 INFO: You can set load_aug=True in a trainer to augment your dataset (English only yet) and improve performance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "convert examples to features: 100%|██████████| 7359/7359 [00:51<00:00, 144.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-02 15:29:32,228 INFO: Dataset Label Details: {'positive': 5784, 'neutral': 927, 'negative': 648, 'Sum': 7359}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "convert examples to features: 100%|██████████| 1807/1807 [00:13<00:00, 137.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-02 15:29:46,540 INFO: Dataset Label Details: {'positive': 1370, 'neutral': 283, 'negative': 154, 'Sum': 1807}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-02 15:29:49,093 INFO: Save cache dataset to fast_lcf_atepc.AttractionReviewEn.dataset.4e27f63b6abb3532d0dc3cc9b4cc40a1643f8b65a830edb3481defa821519e8e.cache\n",
      "2023-05-02 15:29:49,644 INFO: cuda memory allocated:764963840\n",
      "2023-05-02 15:29:49,645 INFO: ABSADatasetsVersion:None\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,646 INFO: IOB_label_to_index:{'B-ASP': 1, 'I-ASP': 2, 'O': 3, '[CLS]': 4, '[SEP]': 5}\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,646 INFO: MV:<metric_visualizer.metric_visualizer.MetricVisualizer object at 0x00000245E8A480D0>\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,647 INFO: PyABSAVersion:2.3.1\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,647 INFO: SRD:3\t-->\tCalling Count:18332\n",
      "2023-05-02 15:29:49,648 INFO: TorchVersion:2.0.0+cuda11.8\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,649 INFO: TransformersVersion:4.28.1\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,650 INFO: auto_device:True\t-->\tCalling Count:3\n",
      "2023-05-02 15:29:49,650 INFO: batch_size:16\t-->\tCalling Count:4\n",
      "2023-05-02 15:29:49,651 INFO: cache_dataset:True\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,652 INFO: checkpoint_save_mode:1\t-->\tCalling Count:4\n",
      "2023-05-02 15:29:49,652 INFO: cross_validate_fold:-1\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,653 INFO: dataset_file:{'train': ['integrated_datasets\\\\atepc_datasets\\\\1.TripAdvisor\\\\data_apc_train.txt.apc.atepc'], 'test': ['integrated_datasets\\\\atepc_datasets\\\\1.TripAdvisor\\\\data_apc_test.txt.apc.atepc'], 'valid': []}\t-->\tCalling Count:6\n",
      "2023-05-02 15:29:49,653 INFO: dataset_name:AttractionReviewEn\t-->\tCalling Count:3\n",
      "2023-05-02 15:29:49,655 INFO: device:cuda:0\t-->\tCalling Count:4\n",
      "2023-05-02 15:29:49,655 INFO: device_name:NVIDIA GeForce RTX 3070 Laptop GPU\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,656 INFO: dropout:0.5\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,657 INFO: dynamic_truncate:True\t-->\tCalling Count:18332\n",
      "2023-05-02 15:29:49,658 INFO: embed_dim:768\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,658 INFO: evaluate_begin:0\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,659 INFO: from_checkpoint:english\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,660 INFO: gradient_accumulation_steps:1\t-->\tCalling Count:3\n",
      "2023-05-02 15:29:49,660 INFO: hidden_dim:768\t-->\tCalling Count:6\n",
      "2023-05-02 15:29:49,661 INFO: index_to_IOB_label:{1: 'B-ASP', 2: 'I-ASP', 3: 'O', 4: '[CLS]', 5: '[SEP]'}\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,661 INFO: index_to_label:{0: 'negative', 1: 'neutral', 2: 'positive'}\t-->\tCalling Count:2\n",
      "2023-05-02 15:29:49,662 INFO: inference_model:None\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,664 INFO: initializer:xavier_uniform_\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,664 INFO: l2reg:1e-05\t-->\tCalling Count:2\n",
      "2023-05-02 15:29:49,665 INFO: label_list:['B-ASP', 'I-ASP', 'O', '[CLS]', '[SEP]']\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,665 INFO: label_to_index:{'negative': 0, 'neutral': 1, 'positive': 2}\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,666 INFO: lcf:cdw\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,666 INFO: learning_rate:2e-05\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,667 INFO: load_aug:False\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,668 INFO: log_step:-1\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,668 INFO: logger:<Logger fast_lcf_atepc (INFO)>\t-->\tCalling Count:9\n",
      "2023-05-02 15:29:49,669 INFO: max_seq_len:80\t-->\tCalling Count:64164\n",
      "2023-05-02 15:29:49,669 INFO: model:<class 'pyabsa.tasks.AspectTermExtraction.models.__lcf__.fast_lcf_atepc.FAST_LCF_ATEPC'>\t-->\tCalling Count:5\n",
      "2023-05-02 15:29:49,670 INFO: model_name:fast_lcf_atepc\t-->\tCalling Count:9168\n",
      "2023-05-02 15:29:49,671 INFO: model_path_to_save:checkpoints\t-->\tCalling Count:2\n",
      "2023-05-02 15:29:49,671 INFO: notice:This is an training example for aspect term extraction\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,672 INFO: num_epoch:10\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,672 INFO: num_labels:6\t-->\tCalling Count:2\n",
      "2023-05-02 15:29:49,673 INFO: optimizer:adamw\t-->\tCalling Count:2\n",
      "2023-05-02 15:29:49,673 INFO: output_dim:3\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,674 INFO: overwrite_cache:False\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,675 INFO: path_to_save:None\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,676 INFO: patience:2\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,678 INFO: pretrained_bert:microsoft/deberta-v3-base\t-->\tCalling Count:5\n",
      "2023-05-02 15:29:49,678 INFO: save_mode:1\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,679 INFO: seed:1\t-->\tCalling Count:6\n",
      "2023-05-02 15:29:49,680 INFO: sep_indices:2\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,680 INFO: show_metric:False\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,681 INFO: spacy_model:en_core_web_sm\t-->\tCalling Count:3\n",
      "2023-05-02 15:29:49,682 INFO: srd_alignment:True\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,683 INFO: task_code:ATEPC\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,683 INFO: task_name:Aspect Term Extraction and Polarity Classification\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,684 INFO: use_amp:False\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,685 INFO: use_bert_spc:True\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,687 INFO: use_syntax_based_SRD:False\t-->\tCalling Count:9166\n",
      "2023-05-02 15:29:49,687 INFO: verbose:False\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,688 INFO: warmup_step:-1\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,688 INFO: window:lr\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,698 INFO: cuda memory allocated:764963840\n",
      "2023-05-02 15:29:49,698 INFO: ABSADatasetsVersion:None\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,699 INFO: IOB_label_to_index:{'B-ASP': 1, 'I-ASP': 2, 'O': 3, '[CLS]': 4, '[SEP]': 5}\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,700 INFO: MV:<metric_visualizer.metric_visualizer.MetricVisualizer object at 0x00000245E8A480D0>\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,700 INFO: PyABSAVersion:2.3.1\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,701 INFO: SRD:3\t-->\tCalling Count:18332\n",
      "2023-05-02 15:29:49,702 INFO: TorchVersion:2.0.0+cuda11.8\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,703 INFO: TransformersVersion:4.28.1\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,703 INFO: auto_device:True\t-->\tCalling Count:4\n",
      "2023-05-02 15:29:49,704 INFO: batch_size:16\t-->\tCalling Count:4\n",
      "2023-05-02 15:29:49,705 INFO: cache_dataset:True\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,706 INFO: checkpoint_save_mode:1\t-->\tCalling Count:4\n",
      "2023-05-02 15:29:49,707 INFO: cross_validate_fold:-1\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,707 INFO: dataset_file:{'train': ['integrated_datasets\\\\atepc_datasets\\\\1.TripAdvisor\\\\data_apc_train.txt.apc.atepc'], 'test': ['integrated_datasets\\\\atepc_datasets\\\\1.TripAdvisor\\\\data_apc_test.txt.apc.atepc'], 'valid': []}\t-->\tCalling Count:6\n",
      "2023-05-02 15:29:49,708 INFO: dataset_name:AttractionReviewEn\t-->\tCalling Count:3\n",
      "2023-05-02 15:29:49,709 INFO: device:cuda:0\t-->\tCalling Count:8\n",
      "2023-05-02 15:29:49,709 INFO: device_name:NVIDIA GeForce RTX 3070 Laptop GPU\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,709 INFO: dropout:0.5\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,710 INFO: dynamic_truncate:True\t-->\tCalling Count:18332\n",
      "2023-05-02 15:29:49,713 INFO: embed_dim:768\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,714 INFO: evaluate_begin:0\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,714 INFO: from_checkpoint:english\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,715 INFO: gradient_accumulation_steps:1\t-->\tCalling Count:3\n",
      "2023-05-02 15:29:49,715 INFO: hidden_dim:768\t-->\tCalling Count:6\n",
      "2023-05-02 15:29:49,716 INFO: index_to_IOB_label:{1: 'B-ASP', 2: 'I-ASP', 3: 'O', 4: '[CLS]', 5: '[SEP]'}\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,717 INFO: index_to_label:{0: 'negative', 1: 'neutral', 2: 'positive'}\t-->\tCalling Count:2\n",
      "2023-05-02 15:29:49,718 INFO: inference_model:None\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,719 INFO: initializer:xavier_uniform_\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,719 INFO: l2reg:1e-05\t-->\tCalling Count:2\n",
      "2023-05-02 15:29:49,720 INFO: label_list:['B-ASP', 'I-ASP', 'O', '[CLS]', '[SEP]']\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,721 INFO: label_to_index:{'negative': 0, 'neutral': 1, 'positive': 2}\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,722 INFO: lcf:cdw\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,722 INFO: learning_rate:2e-05\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,723 INFO: load_aug:False\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,723 INFO: log_step:-1\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,724 INFO: logger:<Logger fast_lcf_atepc (INFO)>\t-->\tCalling Count:9\n",
      "2023-05-02 15:29:49,724 INFO: max_seq_len:80\t-->\tCalling Count:64164\n",
      "2023-05-02 15:29:49,726 INFO: model:<class 'pyabsa.tasks.AspectTermExtraction.models.__lcf__.fast_lcf_atepc.FAST_LCF_ATEPC'>\t-->\tCalling Count:5\n",
      "2023-05-02 15:29:49,727 INFO: model_name:fast_lcf_atepc\t-->\tCalling Count:9168\n",
      "2023-05-02 15:29:49,727 INFO: model_path_to_save:checkpoints\t-->\tCalling Count:2\n",
      "2023-05-02 15:29:49,727 INFO: notice:This is an training example for aspect term extraction\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,728 INFO: num_epoch:10\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,728 INFO: num_labels:6\t-->\tCalling Count:2\n",
      "2023-05-02 15:29:49,729 INFO: optimizer:adamw\t-->\tCalling Count:2\n",
      "2023-05-02 15:29:49,730 INFO: output_dim:3\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,730 INFO: overwrite_cache:False\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,731 INFO: path_to_save:None\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,733 INFO: patience:2\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,735 INFO: pretrained_bert:microsoft/deberta-v3-base\t-->\tCalling Count:5\n",
      "2023-05-02 15:29:49,736 INFO: save_mode:1\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,737 INFO: seed:1\t-->\tCalling Count:6\n",
      "2023-05-02 15:29:49,737 INFO: sep_indices:2\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,738 INFO: show_metric:False\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,738 INFO: spacy_model:en_core_web_sm\t-->\tCalling Count:3\n",
      "2023-05-02 15:29:49,741 INFO: srd_alignment:True\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,741 INFO: task_code:ATEPC\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,742 INFO: task_name:Aspect Term Extraction and Polarity Classification\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,743 INFO: tokenizer:DebertaV2TokenizerFast(name_or_path='microsoft/deberta-v3-base', vocab_size=128000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,744 INFO: use_amp:False\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,744 INFO: use_bert_spc:True\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,745 INFO: use_syntax_based_SRD:False\t-->\tCalling Count:9166\n",
      "2023-05-02 15:29:49,745 INFO: verbose:False\t-->\tCalling Count:1\n",
      "2023-05-02 15:29:49,746 INFO: warmup_step:-1\t-->\tCalling Count:0\n",
      "2023-05-02 15:29:49,746 INFO: window:lr\t-->\tCalling Count:0\n",
      "[2023-05-02 15:29:50] (2.3.1) ********** \u001B[32mAvailable ATEPC model checkpoints for Version:2.3.1 (this version)\u001B[0m **********\n",
      "[2023-05-02 15:29:50] (2.3.1) \u001B[32mDownloading checkpoint:english \u001B[0m\n",
      "[2023-05-02 15:29:50] (2.3.1) \u001B[31mNotice: The pretrained model are used for testing, it is recommended to train the model on your own custom datasets\u001B[0m\n",
      "[2023-05-02 15:29:50] (2.3.1) Checkpoint already downloaded, skip\n",
      "2023-05-02 15:29:52,508 INFO: Checkpoint downloaded at: checkpoints\\ATEPC_ENGLISH_CHECKPOINT\\fast_lcf_atepc_English_cdw_apcacc_82.36_apcf1_81.89_atef1_75.43\n",
      "2023-05-02 15:29:55,751 INFO: Resume trainer from Checkpoint: checkpoints\\ATEPC_ENGLISH_CHECKPOINT\\fast_lcf_atepc_English_cdw_apcacc_82.36_apcf1_81.89_atef1_75.43!\n",
      "2023-05-02 15:29:55,752 INFO: ***** Running training for Aspect Term Extraction and Polarity Classification *****\n",
      "2023-05-02 15:29:55,753 INFO:   Num examples = 7359\n",
      "2023-05-02 15:29:55,755 INFO:   Batch size = 16\n",
      "2023-05-02 15:29:55,755 INFO:   Num steps = 4590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Smooth Loss: 1.2031:   5%|▌         | 25/460 [00:38<11:14,  1.55s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 14\u001B[0m\n\u001B[0;32m      9\u001B[0m config\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m  \u001B[38;5;66;03m# If verbose == True, PyABSA will output the model strcture and seversal processed data examples\u001B[39;00m\n\u001B[0;32m     10\u001B[0m config\u001B[38;5;241m.\u001B[39mnotice \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis is an training example for aspect term extraction\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# for memos usage\u001B[39;00m\n\u001B[0;32m     12\u001B[0m )\n\u001B[1;32m---> 14\u001B[0m trainer \u001B[38;5;241m=\u001B[39m \u001B[43mATEPC\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mATEPCTrainer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfrom_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43menglish\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# if you want to resume training from our pretrained checkpoints, you can pass the checkpoint name here\u001B[39;49;00m\n\u001B[0;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauto_device\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDeviceTypeOption\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAUTO\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# use cuda if available\u001B[39;49;00m\n\u001B[0;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcheckpoint_save_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mModelSaveOption\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSAVE_MODEL_STATE_DICT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# save state dict only instead of the whole model\u001B[39;49;00m\n\u001B[0;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mload_aug\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# there are some augmentation dataset for integrated datasets, you use them by setting load_aug=True to improve performance\u001B[39;49;00m\n\u001B[0;32m     21\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\project\\PyABSA\\pyabsa\\tasks\\AspectTermExtraction\\trainer\\atepc_trainer.py:69\u001B[0m, in \u001B[0;36mATEPCTrainer.__init__\u001B[1;34m(self, config, dataset, from_checkpoint, checkpoint_save_mode, auto_device, path_to_save, load_aug)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mtask_code \u001B[38;5;241m=\u001B[39m TaskCodeOption\u001B[38;5;241m.\u001B[39mAspect_Term_Extraction_and_Classification\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mtask_name \u001B[38;5;241m=\u001B[39m TaskNameOption()\u001B[38;5;241m.\u001B[39mget(\n\u001B[0;32m     66\u001B[0m     TaskCodeOption\u001B[38;5;241m.\u001B[39mAspect_Term_Extraction_and_Classification\n\u001B[0;32m     67\u001B[0m )\n\u001B[1;32m---> 69\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\project\\PyABSA\\pyabsa\\framework\\trainer_class\\trainer_template.py:241\u001B[0m, in \u001B[0;36mTrainer._run\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    239\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mseed \u001B[38;5;241m=\u001B[39m s\n\u001B[0;32m    240\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mcheckpoint_save_mode:\n\u001B[1;32m--> 241\u001B[0m     model_path\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_instructor\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    242\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    243\u001B[0m     \u001B[38;5;66;03m# always return the last trained model if you don't save trained model\u001B[39;00m\n\u001B[0;32m    244\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minference_model_class(\n\u001B[0;32m    245\u001B[0m         checkpoint\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_instructor(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig)\u001B[38;5;241m.\u001B[39mrun()\n\u001B[0;32m    246\u001B[0m     )\n",
      "File \u001B[1;32mD:\\project\\PyABSA\\pyabsa\\tasks\\AspectTermExtraction\\instructor\\atepc_instructor.py:794\u001B[0m, in \u001B[0;36mATEPCTrainingInstructor.run\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    793\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 794\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\project\\PyABSA\\pyabsa\\framework\\instructor_class\\instructor_template.py:372\u001B[0m, in \u001B[0;36mBaseTrainingInstructor._train\u001B[1;34m(self, criterion)\u001B[0m\n\u001B[0;32m    369\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_k_fold_train_and_evaluate(criterion)\n\u001B[0;32m    370\u001B[0m \u001B[38;5;66;03m# Train and evaluate the model if there is only one validation dataloader\u001B[39;00m\n\u001B[0;32m    371\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 372\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_and_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\project\\PyABSA\\pyabsa\\tasks\\AspectTermExtraction\\instructor\\atepc_instructor.py:334\u001B[0m, in \u001B[0;36mATEPCTrainingInstructor._train_and_evaluate\u001B[1;34m(self, criterion)\u001B[0m\n\u001B[0;32m    322\u001B[0m         loss_ate, loss_apc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(\n\u001B[0;32m    323\u001B[0m             input_ids_spc,\n\u001B[0;32m    324\u001B[0m             token_type_ids\u001B[38;5;241m=\u001B[39msegment_ids,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    331\u001B[0m             lcf_cdw_vec\u001B[38;5;241m=\u001B[39mlcf_cdw_vec,\n\u001B[0;32m    332\u001B[0m         )\n\u001B[0;32m    333\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 334\u001B[0m     loss_ate, loss_apc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    335\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids_spc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    336\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msegment_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    337\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    338\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabel_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    339\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpolarity\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpolarity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    340\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalid_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    341\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43ml_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    342\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlcf_cdm_vec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlcf_cdm_vec\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    343\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlcf_cdw_vec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlcf_cdw_vec\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    344\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# for multi-gpu, average loss by gpu instance number\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mauto_device \u001B[38;5;241m==\u001B[39m DeviceTypeOption\u001B[38;5;241m.\u001B[39mALL_CUDA:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PyABSA\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\project\\PyABSA\\pyabsa\\tasks\\AspectTermExtraction\\models\\__lcf__\\fast_lcf_atepc.py:75\u001B[0m, in \u001B[0;36mFAST_LCF_ATEPC.forward\u001B[1;34m(self, input_ids_spc, token_type_ids, attention_mask, labels, polarity, valid_ids, attention_mask_label, lcf_cdm_vec, lcf_cdw_vec)\u001B[0m\n\u001B[0;32m     73\u001B[0m     input_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_ids_for_local_context_extractor(input_ids_spc)\n\u001B[0;32m     74\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_batch_token_labels_bert_base_indices(labels)\n\u001B[1;32m---> 75\u001B[0m     global_context_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbert4global\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     76\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_hidden_state\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m     78\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     79\u001B[0m     global_context_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbert4global(\n\u001B[0;32m     80\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids_spc, attention_mask\u001B[38;5;241m=\u001B[39mattention_mask\n\u001B[0;32m     81\u001B[0m     )[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_hidden_state\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PyABSA\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PyABSA\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:1083\u001B[0m, in \u001B[0;36mDebertaV2Model.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1073\u001B[0m     token_type_ids \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(input_shape, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[0;32m   1075\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(\n\u001B[0;32m   1076\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[0;32m   1077\u001B[0m     token_type_ids\u001B[38;5;241m=\u001B[39mtoken_type_ids,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1080\u001B[0m     inputs_embeds\u001B[38;5;241m=\u001B[39minputs_embeds,\n\u001B[0;32m   1081\u001B[0m )\n\u001B[1;32m-> 1083\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1084\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1085\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1086\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1087\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1088\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1089\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1090\u001B[0m encoded_layers \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   1092\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mz_steps \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PyABSA\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PyABSA\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:521\u001B[0m, in \u001B[0;36mDebertaV2Encoder.forward\u001B[1;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001B[0m\n\u001B[0;32m    512\u001B[0m     output_states \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[0;32m    513\u001B[0m         create_custom_forward(layer_module),\n\u001B[0;32m    514\u001B[0m         next_kv,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    518\u001B[0m         rel_embeddings,\n\u001B[0;32m    519\u001B[0m     )\n\u001B[0;32m    520\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 521\u001B[0m     output_states \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnext_kv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    524\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    525\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrelative_pos\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrelative_pos\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    526\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrel_embeddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrel_embeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    527\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    528\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    530\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n\u001B[0;32m    531\u001B[0m     output_states, att_m \u001B[38;5;241m=\u001B[39m output_states\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PyABSA\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PyABSA\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:362\u001B[0m, in \u001B[0;36mDebertaV2Layer.forward\u001B[1;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001B[0m\n\u001B[0;32m    353\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    354\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    355\u001B[0m     hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    360\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    361\u001B[0m ):\n\u001B[1;32m--> 362\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    363\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    364\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    365\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    366\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    367\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrelative_pos\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrelative_pos\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    368\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrel_embeddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrel_embeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    369\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    370\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n\u001B[0;32m    371\u001B[0m         attention_output, att_matrix \u001B[38;5;241m=\u001B[39m attention_output\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PyABSA\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PyABSA\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:305\u001B[0m, in \u001B[0;36mDebertaV2Attention.forward\u001B[1;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001B[0m\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m query_states \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    304\u001B[0m     query_states \u001B[38;5;241m=\u001B[39m hidden_states\n\u001B[1;32m--> 305\u001B[0m attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput\u001B[49m\u001B[43m(\u001B[49m\u001B[43mself_output\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n\u001B[0;32m    308\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (attention_output, att_matrix)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PyABSA\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PyABSA\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:270\u001B[0m, in \u001B[0;36mDebertaV2SelfOutput.forward\u001B[1;34m(self, hidden_states, input_tensor)\u001B[0m\n\u001B[0;32m    269\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states, input_tensor):\n\u001B[1;32m--> 270\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdense\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    271\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(hidden_states)\n\u001B[0;32m    272\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mLayerNorm(hidden_states \u001B[38;5;241m+\u001B[39m input_tensor)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PyABSA\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PyABSA\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from pyabsa import ModelSaveOption, DeviceTypeOption\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config.batch_size = 16\n",
    "config.patience = 2\n",
    "config.log_step = -1\n",
    "config.seed = [1]\n",
    "config.verbose = False  # If verbose == True, PyABSA will output the model strcture and seversal processed data examples\n",
    "config.notice = (\n",
    "    \"This is an training example for aspect term extraction\"  # for memos usage\n",
    ")\n",
    "\n",
    "trainer = ATEPC.ATEPCTrainer(\n",
    "    config=config,\n",
    "    dataset=dataset,\n",
    "    from_checkpoint=\"english\",  # if you want to resume training from our pretrained checkpoints, you can pass the checkpoint name here\n",
    "    auto_device=DeviceTypeOption.AUTO,  # use cuda if available\n",
    "    checkpoint_save_mode=ModelSaveOption.SAVE_MODEL_STATE_DICT,  # save state dict only instead of the whole model\n",
    "    load_aug=False,  # there are some augmentation dataset for integrated datasets, you use them by setting load_aug=True to improve performance\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
