[2023-06-07 19:38:39] (2.3.1) PyABSA(2.3.1): If your code crashes on Colab, please use the GPU runtime. Then run "pip install pyabsa[dev] -U" and restart the kernel.
Or if it does not work, you can use v1.16.27

[New Feature] Aspect Sentiment Triplet Extraction since v2.1.0 (https://github.com/yangheng95/PyABSA/tree/v2/examples-v2/aspect_sentiment_triplet_extration)
[New Feature] Aspect CategoryOpinion Sentiment Quadruple Extraction since v2.2.0 (https://github.com/yangheng95/PyABSA/tree/v2/examples-v2/aspect_opinion_sentiment_category_extraction)

[2023-06-07 19:38:49] (2.3.1) Load sentiment classifier from /drive0-storage/PyABSA/checkpoints/fast_lsa_t_v2_AttractionReviewId_acc_79.8_f1_71.78
[2023-06-07 19:38:49] (2.3.1) config: checkpoints/fast_lsa_t_v2_AttractionReviewId_acc_79.8_f1_71.78/fast_lsa_t_v2.config
[2023-06-07 19:38:49] (2.3.1) state_dict: checkpoints/fast_lsa_t_v2_AttractionReviewId_acc_79.8_f1_71.78/fast_lsa_t_v2.state_dict
[2023-06-07 19:38:49] (2.3.1) model: None
[2023-06-07 19:38:49] (2.3.1) tokenizer: checkpoints/fast_lsa_t_v2_AttractionReviewId_acc_79.8_f1_71.78/fast_lsa_t_v2.tokenizer
[2023-06-07 19:38:49] (2.3.1) Set Model Device: cuda
[2023-06-07 19:38:49] (2.3.1) Device Name: N.A.
[2023-06-07 19:38:54] (2.3.1) Try to load 521-test.attraction_id dataset from local disk
FindFile Warning --> multiple targets ['integrated_datasets/apc_datasets/521-test.attraction_id', 'integrated_datasets/apc_datasets/521-test.attraction_id/.ipynb_checkpoints'] found, only return the shortest path: <integrated_datasets/apc_datasets/521-test.attraction_id>
[2023-06-07 19:39:01] (2.3.1) inference result saved in: /drive0-storage/PyABSA/Aspect-based Sentiment Classification.FAST_LSA_T_V2.result.json
[2023-06-07 19:39:01] (2.3.1) Total samples:1172
[2023-06-07 19:39:01] (2.3.1) Labeled samples:1172
[2023-06-07 19:39:01] (2.3.1) Prediction Accuracy:75.8532423208191%
[2023-06-07 19:39:01] (2.3.1) 
---------------------------- Start Classification Report ----------------------------


[2023-06-07 19:39:01] (2.3.1)
               precision    recall  f1-score   support

    Negative     0.7009    0.6000    0.6466       125
     Neutral     0.5698    0.5345    0.5516       275
    Positive     0.8265    0.8640    0.8448       772

    accuracy                         0.7585      1172
   macro avg     0.6991    0.6662    0.6810      1172
weighted avg     0.7529    0.7585    0.7549      1172

[2023-06-07 19:39:01] (2.3.1) 
---------------------------- End Classification Report ----------------------------

[2023-06-07 19:39:01] (2.3.1)

[2023-06-07 19:39:01] (2.3.1)
 [[ 75  20  30]
 [ 18 147 110]
 [ 14  91 667]]
[2023-06-07 19:39:01] (2.3.1) 
---------------------------- End Confusion Matrix ----------------------------

[2023-06-07 19:39:01] (2.3.1) Classification report is not available because your examples does not contain all classesor have not reference labels. Exception: ufunc 'add' did not contain a loop with signature matching types (dtype('<U82'), dtype('int64')) -> None
